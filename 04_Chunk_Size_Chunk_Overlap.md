## ðŸ“˜ Chunk Size & Chunk Overlap 

* Imparare a **caricare un documento** in AnythingLLM.
* Comprendere a fondo i concetti di **chunking** e **chunk overlap**.
* Applicare strategie di segmentazione dei documenti per ottimizzare lâ€™accuratezza e le prestazioni di una RAG (Retrieval-Augmented Generation).

---

## ðŸ“‚ Embedding del documento

Per aggiungere un documento:

1. Vai sul tuo workspace in AnythingLLM.
2. Premi â€œEmbed Documentâ€.
3. Carica il tuo file (PDF, Markdown, testo, ecc.).

**Prima di fare embedding**, Ã¨ fondamentale configurare correttamente il chunking nei **Settings > Text Splitter and Chunking**.

---

## ðŸ” Chunking: cosâ€™Ã¨ e perchÃ© Ã¨ importante

### ðŸ“Œ Cos'Ã¨ il *chunk size*?

* Ãˆ la **dimensione (in token)** delle porzioni di testo in cui il documento viene diviso.
* Ogni chunk viene **indicizzato separatamente** nella vector database.
* Permette al modello di **recuperare informazioni** in modo mirato.

### ðŸ’¡ Problema senza chunking

* Se carichi un documento intero come un unico chunk:

  * LLM tende a "capire" bene l'inizio e la fine.
  * Le sezioni centrali sono spesso meno accurate (perdita di contesto).
  * Peggiore accuratezza e performance nella RAG.

---

## ðŸ” Chunk Overlap: cosâ€™Ã¨?

* Ãˆ la **sovrapposizione tra due chunk consecutivi**.
* Garantisce che **informazioni critiche al confine** tra due chunk non vadano perse.
* Migliora la **continuitÃ  del contesto** tra blocchi di testo.

Esempio:

* Chunk 1: token 0â€“1000
* Chunk 2: token 900â€“1900
  âž¡ï¸ Overlap = 100 token = 10%

---

## ðŸ“ Regole pratiche per scegliere Chunk Size e Overlap

| Tipologia documento          | Chunk Size consigliato | Overlap consigliato (1â€“5%) |
| ---------------------------- | ---------------------- | -------------------------- |
| ðŸ“– Libri / Lunghi articoli   | 1000â€“5000 tokens       | 50â€“250 tokens              |
| ðŸ“° Articoli / Racconti brevi | 500â€“1000 tokens        | 10â€“50 tokens               |
| ðŸ“‹ Liste / Tabelle / Prezzi  | 100â€“500 tokens         | 5â€“25 tokens (o anche 0%)   |

> âœ¨ *Ogni documento Ã¨ unico*. Fai dei test: prova diverse combinazioni per trovare quella piÃ¹ efficace.

---

## ðŸ’¸ Prezzo e Performance: perchÃ© chunk piccoli sono meglio

* **Modelli con contesto esteso** (es. 1M token di Google):

  * Possono elaborare documenti grandi, ma a costo elevato.
  * Caricare 50k token per ogni query = costo altissimo.

* **Chunking ottimale**:

  * Permette al modello di cercare solo nei chunk rilevanti.
  * Meno token da elaborare = **query piÃ¹ veloce e meno costosa**.

---

## ðŸŽ¯ Best Practices

1. **Non caricare mai un intero documento come un unico chunk.**
2. Scegli il chunk size in base al contenuto:

   * Testo narrativo = chunk piÃ¹ grandi.
   * Tabelle, liste, prodotti = chunk piccoli.
3. Usa un overlap tra **1% e 5%**.
4. Gioca con i parametri: non esiste una regola unica.
5. Se il modello ha contesto limitato, usa chunk piÃ¹ piccoli.

---

## ðŸ“Œ Conclusioni

* Chunking Ã¨ **fondamentale** per la precisione di una RAG.
* Overlap garantisce coerenza e riduce le perdite di contesto.
* Impostare bene questi parametri Ã¨ cruciale per:

  * Accuratezza.
  * Prestazioni.
  * Costi di esecuzione.
